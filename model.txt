(upsample_blocks): ModuleList(
    (0-2): 3 x ResidualBlock(
      (group_norm1): GroupNorm(8, 512, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=256, bias=True)
      (group_norm2): GroupNorm(8, 256, eps=1e-05, affine=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (attention): Identity()
    )
    (3): UpSampleBlock(
      (upsample): Sequential(
        (0): Upsample(scale_factor=2.0, mode='nearest')
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (4-5): 2 x ResidualBlock(
      (group_norm1): GroupNorm(8, 512, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=256, bias=True)
      (group_norm2): GroupNorm(8, 256, eps=1e-05, affine=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (attention): AttentionBlock(
        (group_norm): GroupNorm(8, 256, eps=1e-05, affine=True)
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
      )
    )
    (6): ResidualBlock(
      (group_norm1): GroupNorm(8, 384, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=256, bias=True)
      (group_norm2): GroupNorm(8, 256, eps=1e-05, affine=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (attention): AttentionBlock(
        (group_norm): GroupNorm(8, 256, eps=1e-05, affine=True)
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
      )
    )
    (7): UpSampleBlock(
      (upsample): Sequential(
        (0): Upsample(scale_factor=2.0, mode='nearest')
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (8): ResidualBlock(
      (group_norm1): GroupNorm(8, 384, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=128, bias=True)
      (group_norm2): GroupNorm(8, 128, eps=1e-05, affine=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
      (attention): AttentionBlock(
        (group_norm): GroupNorm(8, 128, eps=1e-05, affine=True)
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
      )
    )
    (9): ResidualBlock(
      (group_norm1): GroupNorm(8, 256, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=128, bias=True)
      (group_norm2): GroupNorm(8, 128, eps=1e-05, affine=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (attention): AttentionBlock(
        (group_norm): GroupNorm(8, 128, eps=1e-05, affine=True)
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
      )
    )
    (10): ResidualBlock(
      (group_norm1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=128, bias=True)
      (group_norm2): GroupNorm(8, 128, eps=1e-05, affine=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))
      (attention): AttentionBlock(
        (group_norm): GroupNorm(8, 128, eps=1e-05, affine=True)
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
      )
    )
    (11): UpSampleBlock(
      (upsample): Sequential(
        (0): Upsample(scale_factor=2.0, mode='nearest')
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (12): ResidualBlock(
      (group_norm1): GroupNorm(8, 192, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=64, bias=True)
      (group_norm2): GroupNorm(8, 64, eps=1e-05, affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
      (attention): Identity()
    )
    (13-14): 2 x ResidualBlock(
      (group_norm1): GroupNorm(8, 128, eps=1e-05, affine=True)
      (act): SiLU()
      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (dropout): Dropout(p=0.1, inplace=False)
      (time_emb_matching): Linear(in_features=256, out_features=64, bias=True)
      (group_norm2): GroupNorm(8, 64, eps=1e-05, affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
      (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (attention): Identity()
    )
  )
  (last_layer): Sequential(
    (0): GroupNorm(8, 64, eps=1e-05, affine=True)
    (1): SiLU()
    (2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)
  )
)